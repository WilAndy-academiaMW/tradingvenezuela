import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import datetime as dt
from io import StringIO
import os # Para verificar si el archivo CSV ya existe

# --- CONFIGURACI√ìN DE COLUMNAS Y URL ---
URL = "https://www.bolsadecaracas.com/resumen-mercado/"

# 1. Nombres de las columnas que Pandas debe buscar para identificar la tabla (en min√∫sculas)
COLUMNAS_BUSCADAS_LISTA = [
    'nombre',                   
    's√≠mbolo',                  
    '√∫ltimo precio (bs)',       
    'monto efectivo (bs)',      
    'variaci√≥n',
    't√≠tulos negociados'
]
COLUMNAS_BUSCADAS = set(COLUMNAS_BUSCADAS_LISTA)

# 2. Nombres finales que se usar√°n en el DataFrame antes del pivoteo
NOMBRES_FINALES_DF = {
    'nombre': 'Nombre', 
    's√≠mbolo': 'S√≠mbolo', 
    '√∫ltimo precio (bs)': '√öltimo precio (Bs)', 
    'monto efectivo (bs)': 'Monto efectivo (Bs)', 
    'variaci√≥n': 'Variaci√≥n', 
    't√≠tulos negociados': 'T√≠tulos negociados'
}

# --- FUNCIONES AUXILIARES ---

def aplanar_columna(col):
    """Convierte encabezados de tuplas o strings en una sola string en min√∫sculas."""
    if isinstance(col, tuple):
        # Une los elementos de la tupla con un espacio y lo convierte a min√∫sculas
        return ' '.join(str(c) for c in col).lower().strip()
    return str(col).lower().strip()

# --- FUNCI√ìN PRINCIPAL ---

def actualizar_datos_bvcs_diariamente():
    print("Iniciando Selenium (abriendo navegador virtual)...")
    
    try:
        # Inicializa Chrome WebDriver. Aseg√∫rate de que tu driver est√© en el PATH.
        driver = webdriver.Chrome()
    except Exception as e:
        print(f"‚ùå Error al iniciar el WebDriver. Verifica tu instalaci√≥n y PATH de ChromeDriver: {e}")
        return

    try:
        driver.get(URL)
        print("P√°gina cargada. Esperando que la tabla din√°mica aparezca...")

        # 1. ESPERA ROBUSTA: Espera hasta 20 segundos a que cargue el elemento principal de la tabla.
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'col-12'))
        )
        print("Tabla principal detectada.")

        # 2. OBTENER EL HTML COMPLETO Y CERRAR EL NAVEGADOR
        html_cargado = driver.page_source
        driver.quit()
        print("Navegador cerrado. Iniciando procesamiento de datos con Pandas.")

        # 3. PASAR EL HTML CARGADO A PANDAS (Obtenemos todas las tablas)
        df_listado = pd.read_html(StringIO(html_cargado), thousands='.', decimal=',')
        print(f"‚úÖ Se encontraron {len(df_listado)} tablas en el HTML cargado.")

        # 4. APLICAR FILTRO INTELIGENTE PARA ENCONTRAR LA TABLA DE DETALLE
        df_detalle = None
        
        for i, df in enumerate(df_listado):
            columnas_df_actual = set([aplanar_columna(col) for col in df.columns.tolist()])
            
            # Buscamos la tabla que contenga TODAS las columnas que definimos
            if COLUMNAS_BUSCADAS.issubset(columnas_df_actual):
                df_detalle = df
                print(f"üéØ ¬°Tabla de detalle encontrada en el √≠ndice N¬∞ {i}!")
                break
        
        if df_detalle is None:
            print("\n‚ùå FALLO EN EL FILTRADO. No se encontr√≥ la tabla con las columnas esperadas.")
            return

        # 5. LIMPIEZA, NORMALIZACI√ìN Y SELECCI√ìN FINAL
        
        # Aplicamos el aplanamiento de columnas al DataFrame seleccionado
        df_detalle.columns = [aplanar_columna(col) for col in df_detalle.columns]
        
        # Seleccionamos las columnas de inter√©s en el orden definido
        df_resultado = df_detalle[COLUMNAS_BUSCADAS_LISTA].copy()
        df_resultado.dropna(how='all', inplace=True)
        
        # Renombrar a los nombres finales (ej: 's√≠mbolo' -> 'S√≠mbolo')
        df_resultado.rename(columns=NOMBRES_FINALES_DF, inplace=True)

        # 6. REESTRUCTURACI√ìN Y ALMACENAMIENTO DIARIO (El bloque de transposici√≥n corregido)
        
        fecha_hoy = dt.date.today().strftime("%Y-%m-%d")
        print("\n--- Guardando archivos CSV separados por m√©trica ---")

        # Iteramos sobre las m√©tricas que ser√°n los VALORES en la matriz final
        for columna_valor in ['√öltimo precio (Bs)', 'Monto efectivo (Bs)', 'Variaci√≥n', 'T√≠tulos negociados']:
            
            # a. Creamos un √≠ndice temporal √∫nico para agrupar todas las acciones en una sola fila
            df_resultado['indice_temporal'] = 0
            
            # b. Crear el DataFrame pivote: S√≠mbolo como Columnas, M√©trica como Valor, y todo en la fila 0
            df_series = df_resultado.pivot(
                index='indice_temporal', 
                columns='S√≠mbolo',  
                values=columna_valor
            )
            
            # c. Formato de Series de Tiempo: Reemplazamos el √≠ndice temporal '0' por la Fecha de hoy
            df_series.index = [fecha_hoy]
            df_series.index.name = 'Fecha' 
            
            # d. Crear el nombre del archivo (ej: Ultimo_precio_Bs.csv)
            nombre_archivo_base = columna_valor.replace(' ', '_').replace('(', '').replace(')', '').replace('.', '')
            nombre_archivo = f"{nombre_archivo_base}.csv"
            
            # --- L√≥gica de Guardado (Appending) ---
            
            if os.path.exists(nombre_archivo):
                # Si el archivo existe, cargamos el antiguo para hacer el APPEND
                df_antiguo = pd.read_csv(nombre_archivo, index_col='Fecha')
                
                # Combinamos el DataFrame antiguo con la nueva fila (df_series)
                df_combinado = pd.concat([df_antiguo, df_series])
                
                # Eliminamos duplicados por fecha (solo se guarda el √∫ltimo registro del d√≠a)
                df_combinado = df_combinado[~df_combinado.index.duplicated(keep='last')]
                
                # Guardamos el archivo
                df_combinado.to_csv(nombre_archivo)
                print(f"‚úÖ Datos de '{columna_valor}' a√±adidos a {nombre_archivo}")
                
            else:
                # Si el archivo no existe, lo creamos por primera vez
                df_series.to_csv(nombre_archivo)
                print(f"‚úÖ Archivo '{columna_valor}' creado por primera vez como {nombre_archivo}")
        
        print(f"\nOperaci√≥n finalizada. Archivos creados/actualizados en el formato de series de tiempo.")

    except Exception as e:
        print(f"Ocurri√≥ un error grave en el proceso: {e}")
        if 'driver' in locals():
            driver.quit()

# --- EJECUTAR EL PROGRAMA ---
if __name__ == "__main__":
    actualizar_datos_bvcs_diariamente()
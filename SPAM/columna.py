import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import datetime as dt
from io import StringIO
import os 
from pathlib import Path # Mejor para manejar rutas y carpetas

# --- CONFIGURACI√ìN DE RUTAS Y DATOS ---
URL = "https://www.bolsadecaracas.com/resumen-mercado/"
CARPETA_BASE_ACCIONES = "acciones"

# 1. Nombres de las columnas que Pandas debe buscar para identificar la tabla (en min√∫sculas)
COLUMNAS_BUSCADAS_LISTA = [
    'nombre',                     
    's√≠mbolo',                    
    '√∫ltimo precio (bs)',         
    'monto efectivo (bs)',        
    'variaci√≥n',
    't√≠tulos negociados'
]
COLUMNAS_BUSCADAS = set(COLUMNAS_BUSCADAS_LISTA)

# 2. Nombres finales que se usar√°n en el DataFrame antes del pivoteo
NOMBRES_FINALES_DF = {
    'nombre': 'Nombre', 
    's√≠mbolo': 'S√≠mbolo', 
    '√∫ltimo precio (bs)': '√öltimo Precio (Bs)', 
    'monto efectivo (bs)': 'Monto Efectivo (Bs)', 
    'variaci√≥n': 'Variaci√≥n (%)', # Modificado para mayor claridad
    't√≠tulos negociados': 'T√≠tulos Negociados'
}
# Definimos las columnas que queremos como datos diarios (m√©tricas)
COLUMNAS_METRICAS = [
    '√öltimo Precio (Bs)', 
    'Monto Efectivo (Bs)', 
    'Variaci√≥n (%)', 
    'T√≠tulos Negociados'
]

# --- FUNCIONES AUXILIARES ---

def aplanar_columna(col):
    """Convierte encabezados de tuplas o strings en una sola string en min√∫sculas."""
    if isinstance(col, tuple):
        # Une los elementos de la tupla con un espacio y lo convierte a min√∫sculas
        return ' '.join(str(c) for c in col).lower().strip()
    return str(col).lower().strip()

# --- FUNCI√ìN PRINCIPAL ---

def actualizar_base_de_datos_por_accion():
    print("Iniciando Selenium (abriendo navegador virtual)...")
    
    # Configuraci√≥n para ejecutar Chrome en modo sin cabeza (headless)
    options = webdriver.ChromeOptions()
    options.add_argument('--headless') # Ejecutar Chrome sin abrir la ventana visible
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--log-level=3') # Suprime la mayor√≠a de los logs de Chrome

    try:
        # Inicializa Chrome WebDriver
        driver = webdriver.Chrome(options=options)
    except Exception as e:
        print(f"‚ùå Error al iniciar el WebDriver. Verifica tu instalaci√≥n y PATH de ChromeDriver: {e}")
        return

    try:
        driver.get(URL)
        print("P√°gina cargada. Esperando que la tabla din√°mica aparezca...")

        # 1. ESPERA ROBUSTA: Espera hasta 20 segundos a que cargue el elemento
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'col-12'))
        )
        print("Tabla principal detectada.")

        # 2. OBTENER EL HTML COMPLETO Y CERRAR EL NAVEGADOR
        html_cargado = driver.page_source
        driver.quit()
        print("Navegador cerrado. Iniciando procesamiento de datos con Pandas.")

        # 3. PASAR EL HTML CARGADO A PANDAS (Obtenemos todas las tablas)
        # Se a√±aden miles='.' y decimal=',' para leer correctamente los n√∫meros venezolanos
        df_listado = pd.read_html(StringIO(html_cargado), thousands='.', decimal=',')
        
        # 4. APLICAR FILTRO INTELIGENTE PARA ENCONTRAR LA TABLA DE DETALLE
        df_detalle = None
        for i, df in enumerate(df_listado):
            columnas_df_actual = set([aplanar_columna(col) for col in df.columns.tolist()])
            
            if COLUMNAS_BUSCADAS.issubset(columnas_df_actual):
                df_detalle = df
                print(f"üéØ ¬°Tabla de detalle encontrada en el √≠ndice N¬∞ {i}!")
                break
        
        if df_detalle is None:
            print("\n‚ùå FALLO EN EL FILTRADO. No se encontr√≥ la tabla con las columnas esperadas.")
            return

        # 5. LIMPIEZA, NORMALIZACI√ìN Y PREPARACI√ìN
        
        # Aplicamos el aplanamiento de columnas al DataFrame seleccionado
        df_detalle.columns = [aplanar_columna(col) for col in df_detalle.columns]
        
        # Seleccionamos y renombramos las columnas de inter√©s
        df_resultado = df_detalle[COLUMNAS_BUSCADAS_LISTA].copy()
        df_resultado.dropna(how='all', inplace=True)
        df_resultado.rename(columns=NOMBRES_FINALES_DF, inplace=True)

        # 6. EXTRACCI√ìN Y ALMACENAMIENTO POR ACCI√ìN (EL NUEVO REQUERIMIENTO)
        
        fecha_hoy = dt.date.today().strftime("%Y-%m-%d")
        print(f"\n--- Procesando {len(df_resultado)} acciones para la fecha {fecha_hoy} ---")
        
        # Aseguramos que la carpeta base exista
        Path(CARPETA_BASE_ACCIONES).mkdir(exist_ok=True)

        # Iteramos sobre cada fila (cada acci√≥n) del DataFrame
        for index, row in df_resultado.iterrows():
            simbolo = row['S√≠mbolo']
            
            # 6a. Definir rutas
            ruta_carpeta_accion = Path(CARPETA_BASE_ACCIONES) / simbolo
            ruta_archivo_csv = ruta_carpeta_accion / f"{simbolo}.csv"
            
            # 6b. Crear la carpeta para la acci√≥n si no existe
            ruta_carpeta_accion.mkdir(exist_ok=True)
            
            # 6c. Preparar la nueva fila de datos (Serie de Pandas)
            # Solo tomamos las columnas de m√©tricas definidas y las agregamos como una Serie
            nueva_fila = row[COLUMNAS_METRICAS].to_frame().T 
            nueva_fila.index = [fecha_hoy]
            nueva_fila.index.name = 'Fecha'
            
            # 6d. L√≥gica de Guardado (Appending)
            if ruta_archivo_csv.exists():
                # Si el archivo existe, cargamos el antiguo para hacer el APPEND
                df_antiguo = pd.read_csv(ruta_archivo_csv, index_col='Fecha')
                
                # Combinamos el DataFrame antiguo con la nueva fila (df_series)
                df_combinado = pd.concat([df_antiguo, nueva_fila])
                
                # Eliminamos duplicados por fecha (solo se guarda el √∫ltimo registro del d√≠a)
                df_combinado = df_combinado[~df_combinado.index.duplicated(keep='last')]
                
                # Guardamos el archivo
                df_combinado.to_csv(ruta_archivo_csv)
                print(f"‚úÖ [{simbolo}] Datos del d√≠a a√±adidos a su archivo.")
            else:
                # Si el archivo no existe, lo creamos por primera vez
                nueva_fila.to_csv(ruta_archivo_csv)
                print(f"‚ûï [{simbolo}] Archivo creado por primera vez.")
        
        print("\nOperaci√≥n finalizada. Todos los datos de las acciones se han actualizado.")

    except Exception as e:
        print(f"Ocurri√≥ un error grave en el proceso: {e}")
        # Aseguramos que el navegador se cierre si hubo un error antes
        if 'driver' in locals():
            driver.quit()

# --- EJECUTAR EL PROGRAMA ---
if __name__ == "__main__":
    actualizar_base_de_datos_por_accion()